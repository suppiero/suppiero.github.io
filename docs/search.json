[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Piero Trujillo",
    "section": "",
    "text": "about me\nHello üëãüèΩ My name is Piero Trujillo and welcome to my personal website!\nI recently graduated from the University of California, Santa Barbara, where I received a Bachelor‚Äôs Degree in Statistics & Data Science.\nI possess extensive knowledge in data science libraries using Python, tidymodels and tidyverse in R, as well as intermediate proficiency in SQL and PySpark for database and big data processing.\nIn my spare time, you can find me playing soccer and spikeball, getting my hands dirty in ceramics, whipping up culinary delights in the kitchen, or being a foodie with my friends downtown.\n\n\neducation\nBachelor‚Äôs in Statistics & Data Science | 2023 | UCSB"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "portfolio",
    "section": "",
    "text": "Check out some of my favorite projects I worked on as an undergraduate student at UC Santa Barbara!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding and Modeling Human Mobility Response to California Wildfires\n\n\nA research poster created for the statistics & data science capstone project.\n\n\n\nPiero Trujillo, Justin Liu, Lyndsey Umsted, Ellen Burrell\n\n\nJun 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Points in Fantasy Premier League\n\n\nUsing machine learning to propel myself to the top of my minileague!\n\n\n\nPiero Trujillo\n\n\nDec 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Legendary Pokemon\n\n\nPredicting whether a pokemon is legendary based on their stats & attributes.\n\n\n\nPiero Trujillo and Randy Ross\n\n\nDec 4, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#links-poster",
    "href": "projects.html#links-poster",
    "title": "Projects",
    "section": "Links: Poster",
    "text": "Links: Poster"
  },
  {
    "objectID": "projects/MOVE_Lab/index.html#project-background",
    "href": "projects/MOVE_Lab/index.html#project-background",
    "title": "Understanding and Modeling Human Mobility Response to California Wildfires",
    "section": "",
    "text": "In this project, I collaborated with a team of four students on a six-month research project sponsored by the Movement Data Science Lab at UCSB where we utilized time series datasets tracking human mobility to analyze changes in movement patterns during California wildfires. Specifically, we focused on the Lake Fire in Los Angeles County, which occurred from August to September in 2020. In this project, we used spatial-temporal data science techniques and machine learning applications to model human mobility in response to wildfires. Our main objective was to apply machine learning techniques to identify and trace changes in mobility time series of wildfire events. The project‚Äôs main finding is that mobility in locations closer to the fire‚Äôs edge and locations in the direction of the fire‚Äôs burn experience a greater impact from wildfires. Similarly, the categories of locations experiencing a significant impact in mobility from wildfires are Historical/Nature, Public Functions, Grocery, Gasoline, Religious, and Childcare. Furthermore, we produced a number of presentations, including a poster presentation for the UC Santa Barbara Data Science Capstone Project Showcase."
  },
  {
    "objectID": "projects/MOVE_Lab/index.html#poster",
    "href": "projects/MOVE_Lab/index.html#poster",
    "title": "Understanding and Modeling Human Mobility Response to California Wildfires",
    "section": "Poster",
    "text": "Poster\nBelow you can find our project poster that we presented at the UCSB Data Science Capstone Showcase!"
  },
  {
    "objectID": "projects/fantasy_premier_league/index.html",
    "href": "projects/fantasy_premier_league/index.html",
    "title": "Predicting Points in Fantasy Premier League",
    "section": "",
    "text": "This machine learning project leverages gameweek-specific data from Fantasy Premier League, considering fundamental player statistics such as bonus points, expected points, goals scored, assists, ict_index, influence, threat, and creativity. Its objective is to develop a model that accurately predicts a player‚Äôs actual weekly point total in that specific week of the Fantasy Premier League. The six models I developed were Linear Regression, Decision Tree, Random Forest, Boosted Trees, Lasso Regression, and Ridge Regression. Upon thorough evaluation using three key metrics: RMSE, MAE, and R-Squared, the Random Forest model emerged as the greatest model, distinguished by its commendable accuracy yielding an RMSE value of 0.519.\nLinks: Project Report and GitHub repo\n\n\n\nCitationBibTeX citation:@online{trujillo2022,\n  author = {Trujillo, Piero},\n  title = {Predicting {Points} in {Fantasy} {Premier} {League}},\n  date = {2022-12-11},\n  url = {https://suppiero.github.io/projects/fantasy_premier_league/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nTrujillo, Piero. 2022. ‚ÄúPredicting Points in Fantasy Premier\nLeague.‚Äù December 11, 2022. https://suppiero.github.io/projects/fantasy_premier_league/."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/index.html",
    "href": "projects/pokemon_legendary_classifier/index.html",
    "title": "Classifying Legendary Pokemon",
    "section": "",
    "text": "The focus of our project was to find a reliable way to classify legendary pokemon based on their different attributes. Many attributes of a pokemon were taken into account. These included their capture rate as well as their attack, defense, and speed stats. With our findings we could compare our results with ordinary pokemon, whose stats neighbored those of a legendary pokemon, in order to strong pokemon that would ordinarily be overlooked. Our data showed that the best classifiers for a legendary pokemon were their capture rate and defense stat. Therefore, legendary pokemon must have low capture rates and high defense stats. With this in mind, we were able to classify legendary pokemon with a success rate of 95.9%."
  },
  {
    "objectID": "projects/MOVE_Lab/index.html",
    "href": "projects/MOVE_Lab/index.html",
    "title": "Understanding and Modeling Human Mobility Response to California Wildfires",
    "section": "",
    "text": "In this project, I collaborated with a team of four students on a six-month research project sponsored by the Movement Data Science Lab at UCSB where we utilized time series datasets tracking human mobility to analyze changes in movement patterns during California wildfires. Specifically, we focused on the Lake Fire in Los Angeles County, which occurred from August to September in 2020. In this project, we used spatial-temporal data science techniques and machine learning applications to model human mobility in response to wildfires. Our main objective was to apply machine learning techniques to identify and trace changes in mobility time series of wildfire events. The project‚Äôs main finding is that mobility in locations closer to the fire‚Äôs edge and locations in the direction of the fire‚Äôs burn experience a greater impact from wildfires. Similarly, the categories of locations experiencing a significant impact in mobility from wildfires are Historical/Nature, Public Functions, Grocery, Gasoline, Religious, and Childcare. Furthermore, we produced a number of presentations, including a poster presentation for the UC Santa Barbara Data Science Capstone Project Showcase."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/project.html#the-complete-pokemon-dataset---rounak-banik",
    "href": "projects/pokemon_legendary_classifier/project.html#the-complete-pokemon-dataset---rounak-banik",
    "title": "Legendary Pokemon Classifier",
    "section": "The Complete Pokemon Dataset - Rounak Banik",
    "text": "The Complete Pokemon Dataset - Rounak Banik\nhttps://www.kaggle.com/rounakbanik/pokemon\nEthical Considerations\n\nRounak Banik collected this data from http://serebii.net/, a very reputable Pokemon fan-site, because Pokemon is very special to him and built the dataset out of passion and curiosity for the game.\nWe believe the analysis of this dataset does not cause harm to anyone because those represented in the data only exist virtually.\nDigital beings known as Pokemon are represented in the dataset. Nothing is being over-represented because the data is focusing solely on Pokemon and not any other groups.\nThis could be considered ethically wrong if you are new to the game and want to experience it naturally.\n\nRelevant Attributes - The only data missing from the dataset is Pokemon generation 8 (released in 2019), which would bring it up to date. - We are attempting to classify whether or not a certain Pokemon is legendary or not. + The variable will be either 0 or 1, where 0 means not legendary, and 1 means legendary. - We will use attributes attack and sp_attack, defense and sp_defense (sp = special), capture rate, hp (hit points), and speed. - We removed one Pokemon whose capture rate was ‚Äú30 (Meteorite)255 (Core)‚Äù, which is not a plain number."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/project.html#eda",
    "href": "projects/pokemon_legendary_classifier/project.html#eda",
    "title": "Legendary Pokemon Classifier",
    "section": "EDA",
    "text": "EDA\n\npokemon.scatter(\"attack\", \"defense\", group=\"is_legendary\")\n\n\n\n\n\npokemon.scatter(\"sp_attack\", \"sp_defense\", group=\"is_legendary\")\n\n\n\n\n\npokemon.scatter(\"hp\", \"defense\", group=\"is_legendary\")\n\n\n\n\n\nax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\nax.scatter(pokemon.column(\"attack\"),\n           pokemon.column(\"defense\"),\n           pokemon.column(\"speed\"),\n           c=pokemon.column(\"is_legendary\"));\n\n\n\n\n\nax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\nax.scatter(pokemon.column(\"capture_rate\"), \n           pokemon.column(\"attack\"), \n           pokemon.column(\"defense\"), \n           c=pokemon.column(\"is_legendary\"));\n\n\n\n\n\nbest_columns = pokemon.select(\"name\", \"attack\", \"defense\", \"capture_rate\", \"is_legendary\")\n\nlegendaries = best_columns.where(\"is_legendary\", are.equal_to(1))\n\ncapture_rate = legendaries.group(\"capture_rate\")\nattack = legendaries.group(\"attack\")\ndefense = legendaries.group(\"defense\")\n\ncapture_rate.show()\n# attack.show()\n# defense.show()\n\n\n\n\ncapture_rate\ncount\n\n\n\n\n3\n53\n\n\n15\n1\n\n\n25\n2\n\n\n30\n1\n\n\n45\n11\n\n\n255\n2\n\n\n\n\n\nThe above table shows that 53 of the 70 legendary Pokemon have the lowest capture rate in the game.\n\nlowest_capture_rate = best_columns.sort(\"capture_rate\")\nlowest_capture_rate.take(range(20)).show()\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nArticuno\n85\n100\n3\n1\n\n\nZapdos\n90\n85\n3\n1\n\n\nMoltres\n100\n90\n3\n1\n\n\nMewtwo\n150\n70\n3\n1\n\n\nRaikou\n85\n75\n3\n1\n\n\nEntei\n115\n85\n3\n1\n\n\nSuicune\n75\n115\n3\n1\n\n\nLugia\n90\n130\n3\n1\n\n\nHo-Oh\n130\n90\n3\n1\n\n\nBeldum\n55\n80\n3\n0\n\n\nMetang\n75\n100\n3\n0\n\n\nMetagross\n145\n150\n3\n0\n\n\nRegirock\n100\n200\n3\n1\n\n\nRegice\n50\n100\n3\n1\n\n\nRegisteel\n75\n150\n3\n1\n\n\nLatias\n100\n120\n3\n1\n\n\nLatios\n130\n100\n3\n1\n\n\nKyogre\n150\n90\n3\n1\n\n\nGroudon\n180\n160\n3\n1\n\n\nJirachi\n100\n100\n3\n1\n\n\n\n\n\nThe above table shows that only 3 of the 20 lowest capture rates are non-legendary.\n\nhighest_defense = best_columns.sort(\"defense\", descending=True)\n\nhighest_defense_20 = highest_defense.take(range(20))\nhighest_defense_20.show()\nhighest_defense_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nSteelix\n125\n230\n25\n0\n\n\nShuckle\n10\n230\n190\n0\n\n\nAggron\n140\n230\n45\n0\n\n\nRegirock\n100\n200\n3\n1\n\n\nAvalugg\n117\n184\n55\n0\n\n\nSlowbro\n75\n180\n75\n0\n\n\nCloyster\n95\n180\n60\n0\n\n\nBastiodon\n52\n168\n45\n0\n\n\nOnix\n45\n160\n45\n0\n\n\nGroudon\n180\n160\n3\n1\n\n\nToxapex\n63\n152\n75\n0\n\n\nTyranitar\n164\n150\n45\n0\n\n\nMetagross\n145\n150\n3\n0\n\n\nRegisteel\n75\n150\n3\n1\n\n\nDoublade\n110\n150\n90\n0\n\n\nCarbink\n50\n150\n60\n0\n\n\nProbopass\n55\n145\n60\n0\n\n\nCofagrigus\n50\n145\n90\n0\n\n\nForretress\n90\n140\n75\n0\n\n\nScizor\n150\n140\n25\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n17\n\n\n1\n3\n\n\n\n\n\n\nhighest_attack = best_columns.sort(\"attack\", descending=True)\n\nhighest_attack_20 = highest_attack.take(range(20))\nhighest_attack_100 = highest_attack.take(range(100))\nhighest_attack_200 = highest_attack.take(range(200))\n\n# Number of legendaries in top defense pokemon\nhighest_attack_20_sum = highest_attack_20.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_attack_100_sum = highest_attack_100.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_attack_200_sum = highest_attack_200.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\n\nprint(\"% legendary in top 20:\", (highest_attack_20_sum / 20) * 100)\nprint(\"% legendary in top 100:\", (highest_attack_100_sum / 100) * 100)\nprint(\"% legendary in top 200:\", (highest_attack_200_sum / 200) * 100)\n\n% legendary in top 20: 35.0\n% legendary in top 100: 28.000000000000004\n% legendary in top 200: 23.0\n\n\nThis may be implying that when sorted by attack, more legendaries are concentrated at the top.\n\nhighest_defense_20 = highest_defense.take(range(20))\nhighest_defense_100 = highest_defense.take(range(100))\nhighest_defense_200 = highest_defense.take(range(200))\n\n# Number of legendaries in top defense pokemon\nhighest_defense_20_sum = highest_defense_20.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_defense_100_sum = highest_defense_100.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_defense_200_sum = highest_defense_200.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\n\nprint(\"% legendary in top 20:\", (highest_defense_20_sum / 20) * 100)\nprint(\"% legendary in top 100:\", (highest_defense_100_sum / 100) * 100)\nprint(\"% legendary in top 200:\", (highest_defense_200_sum / 200) * 100)\n\n% legendary in top 20: 15.0\n% legendary in top 100: 22.0\n% legendary in top 200: 23.5\n\n\nUnlike attack, when sorted by defense, there is not a higher concentration of legendaries at the top.\n\nlowest_defense = best_columns.sort(\"defense\")\n\nlowest_defense_20 = lowest_defense.take(range(20))\nlowest_defense_20.show()\nlowest_defense_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nChansey\n5\n5\n30\n0\n\n\nHappiny\n5\n5\n130\n0\n\n\nBlissey\n10\n10\n30\n0\n\n\nAbra\n20\n15\n200\n0\n\n\nPichu\n40\n15\n190\n0\n\n\nIgglybuff\n30\n15\n170\n0\n\n\nSmoochum\n30\n15\n45\n0\n\n\nJigglypuff\n45\n20\n170\n0\n\n\nCarvanha\n90\n20\n225\n0\n\n\nFeebas\n15\n20\n255\n0\n\n\nWhismur\n51\n23\n190\n0\n\n\nRalts\n25\n25\n235\n0\n\n\nCleffa\n25\n28\n150\n0\n\n\nWeedle\n35\n30\n255\n0\n\n\nSpearow\n60\n30\n255\n0\n\n\nDiglett\n55\n30\n255\n0\n\n\nKadabra\n35\n30\n100\n0\n\n\nGastly\n35\n30\n190\n0\n\n\nHoothoot\n30\n30\n255\n0\n\n\nLedyba\n20\n30\n255\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n20\n\n\n\n\n\n\nlowest_attack = best_columns.sort(\"attack\")\n\nlowest_attack_20 = lowest_attack.take(range(20))\nlowest_attack_20.show()\nlowest_attack_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nChansey\n5\n5\n30\n0\n\n\nHappiny\n5\n5\n130\n0\n\n\nMagikarp\n10\n55\n255\n0\n\n\nShuckle\n10\n230\n190\n0\n\n\nBlissey\n10\n10\n30\n0\n\n\nFeebas\n15\n20\n255\n0\n\n\nMetapod\n20\n55\n120\n0\n\n\nAbra\n20\n15\n200\n0\n\n\nLedyba\n20\n30\n255\n0\n\n\nTogepi\n20\n65\n190\n0\n\n\nMarill\n20\n50\n190\n0\n\n\nSmeargle\n20\n35\n45\n0\n\n\nAzurill\n20\n40\n150\n0\n\n\nMantyke\n20\n50\n25\n0\n\n\nSpewpa\n22\n60\n120\n0\n\n\nWynaut\n23\n48\n125\n0\n\n\nBronzor\n24\n86\n255\n0\n\n\nKakuna\n25\n50\n120\n0\n\n\nCleffa\n25\n28\n150\n0\n\n\nRalts\n25\n25\n235\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n20\n\n\n\n\n\nIt seems that the capture rate of the Pokemon is the best indicator of whether it is legendary or not. The attack and defense of the Pokemon may also be a good indicator."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/project.html#training-and-testing-sets",
    "href": "projects/pokemon_legendary_classifier/project.html#training-and-testing-sets",
    "title": "Legendary Pokemon Classifier",
    "section": "Training and testing sets",
    "text": "Training and testing sets\n\npokemon_classify_columns = pokemon.select(\"attack\", \"defense\", \"capture_rate\", \"is_legendary\")\n\npokemon_classify_columns.stats()\n\n\n\n\nstatistic\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nmin\n5\n5\n3\n0\n\n\nmax\n185\n230\n255\n1\n\n\nmedian\n75\n70\n60\n0\n\n\nsum\n62264\n58420\n79009\n70\n\n\n\n\n\n\nall_legendaries = pokemon_classify_columns.where(\"is_legendary\", are.equal_to(1)).sample(with_replacement=False)\nnon_legendaries = pokemon_classify_columns.where(\"is_legendary\", are.equal_to(0)).sample(with_replacement=False)\n\nnum_legendary = all_legendaries.num_rows\nnum_non_legendary = non_legendaries.num_rows\n\nnum_legendary_training = int(0.667 * num_legendary)\nnum_non_legendary_training = int(0.667 * num_non_legendary)\n\n\n# Take first two thirds legendary and non-legendary pokemon\ntraining_legendary = all_legendaries.take(np.arange(num_legendary_training))\ntraining_non_legendary = non_legendaries.take(np.arange(num_non_legendary_training))\n\n\n# Take last third legendary and non-legendary\ntesting_legendary = all_legendaries.take(np.arange(num_legendary_training, num_legendary))\ntesting_non_legendary = non_legendaries.take(np.arange(num_non_legendary_training, num_non_legendary))\n\n\n# Append training and testing legendary and non-legendary\ntesting_legendary.append(testing_non_legendary)\ntraining_legendary.append(training_non_legendary)\n\n\n# Shuffle training and testing and assign new names\ntraining = training_legendary.shuffle()\ntesting = testing_legendary.shuffle()\n\ntraining.relabel(\"is_legendary\", \"Class\")\ntesting.relabel(\"is_legendary\", \"Class\")\n\n\n\n\nattack\ndefense\ncapture_rate\nClass\n\n\n\n\n92\n108\n100\n0\n\n\n50\n120\n75\n0\n\n\n135\n105\n75\n0\n\n\n15\n20\n255\n0\n\n\n95\n95\n45\n0\n\n\n105\n90\n45\n0\n\n\n115\n60\n60\n0\n\n\n74\n74\n45\n0\n\n\n120\n75\n45\n0\n\n\n47\n75\n150\n0\n\n\n\n\n... (258 rows omitted)\n\n\nWe are putting two thirds of all the Pokemon into the training set, and the other third into the testing set. To make sure both sets have legendary Pokemon, first the legendary pokemon are separated from the non-legendary, and two thirds from each catagory are put into the training set, and the rest into the testing set.\n\nClassifier\n\ndef accuracy(predictions, labels):\n    diff = labels - predictions\n    num_incorrect = np.count_nonzero(diff)\n    num_correct = len(labels) - num_incorrect\n    accuracy = num_correct / len(labels)\n    return accuracy\n\n\ndef distance_nn(point1, point2):\n    \"\"\"The distance between two arrays of numbers.\"\"\"\n    return np.sqrt(np.sum((point1 - point2)**2))\n\ndef all_distances(training, point):\n    \"\"\"The distance between p (an array of numbers) and the numbers in row i of attribute_table.\"\"\"\n    attributes = training.drop('Class')\n    def distance_from_point(row):\n        return distance_nn(point, np.array(row))\n    return attributes.apply(distance_from_point)\n\ndef table_with_distances(training, point):\n    \"\"\"A copy of the training table with the distance from each row to array p.\"\"\"\n    return training.with_column('Distance', all_distances(training, point))\n\ndef closest(training, point, k):\n    \"\"\"A table containing the k closest rows in the training table to array p.\"\"\"\n    with_dists = table_with_distances(training, point)\n    sorted_by_distance = with_dists.sort('Distance')\n    topk = sorted_by_distance.take(np.arange(k))\n    return topk\n\ndef majority(topkclasses):\n    \"\"\"1 if the majority of the \"Class\" column is 1s, and 0 otherwise.\"\"\"\n    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n    if ones &gt; zeros:\n        return 1\n    else:\n        return 0\n\ndef classify(training, p, k):\n    \"\"\"Classify an example with attributes p using k-nearest neighbor classification with the given training table.\"\"\"\n    closestk = closest(training, p, k)\n    topkclasses = closestk.select('Class')\n    return majority(topkclasses)\n\ndef classify_table(training, points, k):\n    \"\"\"Classify a table of unlabled points using KNN\"\"\"\n    def classify_p(p):\n        return classify(training, p, k)\n\n    classes = points.apply(classify_p)\n    return points.with_column('Class', classes)"
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/project.html#classifying-legendary-pokemon",
    "href": "projects/pokemon_legendary_classifier/project.html#classifying-legendary-pokemon",
    "title": "Legendary Pokemon Classifier",
    "section": "Classifying Legendary Pokemon",
    "text": "Classifying Legendary Pokemon\n\nprediction_1 = classify_table(training, testing.drop(\"Class\"), 1)\nprediction_3 = classify_table(training, testing.drop(\"Class\"), 3)\nprediction_5 = classify_table(training, testing.drop(\"Class\"), 5)\n\n\naccuracy_1 = accuracy(prediction_1.column(\"Class\"), testing.column(\"Class\"))\naccuracy_3 = accuracy(prediction_3.column(\"Class\"), testing.column(\"Class\"))\naccuracy_5 = accuracy(prediction_5.column(\"Class\"), testing.column(\"Class\"))\n\nprint(\"k=1 -&gt;\", accuracy_1)\nprint(\"k=3 -&gt;\", accuracy_3)\nprint(\"k=5 -&gt;\", accuracy_5)\n\n\nResults\nThe classifier was run using a few different k-values for the k-nearest neighbor algorithm. Using the 1st nearest-neighbor, the accuracy was about 95%. Going to the 3 nearest neighbors, the accuracy went up to about 95.5%. With 5 nearest neighbors, the accuracy was 95.9%. Increasing the k-value just slightly increases the accuracy of the classifier."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/index.html#the-complete-pokemon-dataset---rounak-banik",
    "href": "projects/pokemon_legendary_classifier/index.html#the-complete-pokemon-dataset---rounak-banik",
    "title": "Classifying Legendary Pokemon",
    "section": "The Complete Pokemon Dataset - Rounak Banik",
    "text": "The Complete Pokemon Dataset - Rounak Banik\nhttps://www.kaggle.com/rounakbanik/pokemon\nEthical Considerations\n\nRounak Banik collected this data from http://serebii.net/, a very reputable Pokemon fan-site, because Pokemon is very special to him and built the dataset out of passion and curiosity for the game.\nWe believe the analysis of this dataset does not cause harm to anyone because those represented in the data only exist virtually.\nDigital beings known as Pokemon are represented in the dataset. Nothing is being over-represented because the data is focusing solely on Pokemon and not any other groups.\nThis could be considered ethically wrong if you are new to the game and want to experience it naturally.\n\nRelevant Attributes - The only data missing from the dataset is Pokemon generation 8 (released in 2019), which would bring it up to date. - We are attempting to classify whether or not a certain Pokemon is legendary or not. + The variable will be either 0 or 1, where 0 means not legendary, and 1 means legendary. - We will use attributes attack and sp_attack, defense and sp_defense (sp = special), capture rate, hp (hit points), and speed. - We removed one Pokemon whose capture rate was ‚Äú30 (Meteorite)255 (Core)‚Äù, which is not a plain number."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/index.html#eda",
    "href": "projects/pokemon_legendary_classifier/index.html#eda",
    "title": "Classifying Legendary Pokemon",
    "section": "EDA",
    "text": "EDA\n\npokemon.scatter(\"attack\", \"defense\", group=\"is_legendary\")\n\n\n\n\n\npokemon.scatter(\"sp_attack\", \"sp_defense\", group=\"is_legendary\")\n\n\n\n\n\npokemon.scatter(\"hp\", \"defense\", group=\"is_legendary\")\n\n\n\n\n\nax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\nax.scatter(pokemon.column(\"attack\"),\n        pokemon.column(\"defense\"),\n        pokemon.column(\"speed\"),\n        c=pokemon.column(\"is_legendary\"));\n\n\n\n\n\nax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\nax.scatter(pokemon.column(\"capture_rate\"),\n        pokemon.column(\"attack\"),\n        pokemon.column(\"defense\"),\n        c=pokemon.column(\"is_legendary\"));\n\n\n\n\n\nbest_columns = pokemon.select(\"name\", \"attack\", \"defense\", \"capture_rate\", \"is_legendary\")\n\nlegendaries = best_columns.where(\"is_legendary\", are.equal_to(1))\n\ncapture_rate = legendaries.group(\"capture_rate\")\nattack = legendaries.group(\"attack\")\ndefense = legendaries.group(\"defense\")\n\ncapture_rate.show()\n# attack.show()\n# defense.show()\n\n\n\n\ncapture_rate\ncount\n\n\n\n\n3\n53\n\n\n15\n1\n\n\n25\n2\n\n\n30\n1\n\n\n45\n11\n\n\n255\n2\n\n\n\n\n\nThe above table shows that 53 of the 70 legendary Pokemon have the lowest capture rate in the game.\n\nlowest_capture_rate = best_columns.sort(\"capture_rate\")\nlowest_capture_rate.take(range(20)).show()\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nArticuno\n85\n100\n3\n1\n\n\nZapdos\n90\n85\n3\n1\n\n\nMoltres\n100\n90\n3\n1\n\n\nMewtwo\n150\n70\n3\n1\n\n\nRaikou\n85\n75\n3\n1\n\n\nEntei\n115\n85\n3\n1\n\n\nSuicune\n75\n115\n3\n1\n\n\nLugia\n90\n130\n3\n1\n\n\nHo-Oh\n130\n90\n3\n1\n\n\nBeldum\n55\n80\n3\n0\n\n\nMetang\n75\n100\n3\n0\n\n\nMetagross\n145\n150\n3\n0\n\n\nRegirock\n100\n200\n3\n1\n\n\nRegice\n50\n100\n3\n1\n\n\nRegisteel\n75\n150\n3\n1\n\n\nLatias\n100\n120\n3\n1\n\n\nLatios\n130\n100\n3\n1\n\n\nKyogre\n150\n90\n3\n1\n\n\nGroudon\n180\n160\n3\n1\n\n\nJirachi\n100\n100\n3\n1\n\n\n\n\n\nThe above table shows that only 3 of the 20 lowest capture rates are non-legendary.\n\nhighest_defense = best_columns.sort(\"defense\", descending=True)\n\nhighest_defense_20 = highest_defense.take(range(20))\nhighest_defense_20.show()\nhighest_defense_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nSteelix\n125\n230\n25\n0\n\n\nShuckle\n10\n230\n190\n0\n\n\nAggron\n140\n230\n45\n0\n\n\nRegirock\n100\n200\n3\n1\n\n\nAvalugg\n117\n184\n55\n0\n\n\nSlowbro\n75\n180\n75\n0\n\n\nCloyster\n95\n180\n60\n0\n\n\nBastiodon\n52\n168\n45\n0\n\n\nOnix\n45\n160\n45\n0\n\n\nGroudon\n180\n160\n3\n1\n\n\nToxapex\n63\n152\n75\n0\n\n\nTyranitar\n164\n150\n45\n0\n\n\nMetagross\n145\n150\n3\n0\n\n\nRegisteel\n75\n150\n3\n1\n\n\nDoublade\n110\n150\n90\n0\n\n\nCarbink\n50\n150\n60\n0\n\n\nProbopass\n55\n145\n60\n0\n\n\nCofagrigus\n50\n145\n90\n0\n\n\nForretress\n90\n140\n75\n0\n\n\nScizor\n150\n140\n25\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n17\n\n\n1\n3\n\n\n\n\n\n\nhighest_attack = best_columns.sort(\"attack\", descending=True)\n\nhighest_attack_20 = highest_attack.take(range(20))\nhighest_attack_100 = highest_attack.take(range(100))\nhighest_attack_200 = highest_attack.take(range(200))\n\n# Number of legendaries in top defense pokemon\nhighest_attack_20_sum = highest_attack_20.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_attack_100_sum = highest_attack_100.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_attack_200_sum = highest_attack_200.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\n\nprint(\"% legendary in top 20:\", (highest_attack_20_sum / 20) * 100)\nprint(\"% legendary in top 100:\", (highest_attack_100_sum / 100) * 100)\nprint(\"% legendary in top 200:\", (highest_attack_200_sum / 200) * 100)\n\n% legendary in top 20: 35.0\n% legendary in top 100: 28.0\n% legendary in top 200: 23.0\n\n\nThis may be implying that when sorted by attack, more legendaries are concentrated at the top.\n\nhighest_defense_20 = highest_defense.take(range(20))\nhighest_defense_100 = highest_defense.take(range(100))\nhighest_defense_200 = highest_defense.take(range(200))\n\n# Number of legendaries in top defense pokemon\nhighest_defense_20_sum = highest_defense_20.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_defense_100_sum = highest_defense_100.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\nhighest_defense_200_sum = highest_defense_200.stats().where(\"statistic\", are.equal_to(\"sum\"))[5][0]\n\nprint(\"% legendary in top 20:\", (highest_defense_20_sum / 20) * 100)\nprint(\"% legendary in top 100:\", (highest_defense_100_sum / 100) * 100)\nprint(\"% legendary in top 200:\", (highest_defense_200_sum / 200) * 100)\n\n% legendary in top 20: 15.0\n% legendary in top 100: 22.0\n% legendary in top 200: 23.5\n\n\nUnlike attack, when sorted by defense, there is not a higher concentration of legendaries at the top.\n\nlowest_defense = best_columns.sort(\"defense\")\n\nlowest_defense_20 = lowest_defense.take(range(20))\nlowest_defense_20.show()\nlowest_defense_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nChansey\n5\n5\n30\n0\n\n\nHappiny\n5\n5\n130\n0\n\n\nBlissey\n10\n10\n30\n0\n\n\nAbra\n20\n15\n200\n0\n\n\nPichu\n40\n15\n190\n0\n\n\nIgglybuff\n30\n15\n170\n0\n\n\nSmoochum\n30\n15\n45\n0\n\n\nJigglypuff\n45\n20\n170\n0\n\n\nCarvanha\n90\n20\n225\n0\n\n\nFeebas\n15\n20\n255\n0\n\n\nWhismur\n51\n23\n190\n0\n\n\nRalts\n25\n25\n235\n0\n\n\nCleffa\n25\n28\n150\n0\n\n\nWeedle\n35\n30\n255\n0\n\n\nSpearow\n60\n30\n255\n0\n\n\nDiglett\n55\n30\n255\n0\n\n\nKadabra\n35\n30\n100\n0\n\n\nGastly\n35\n30\n190\n0\n\n\nHoothoot\n30\n30\n255\n0\n\n\nLedyba\n20\n30\n255\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n20\n\n\n\n\n\n\nlowest_attack = best_columns.sort(\"attack\")\n\nlowest_attack_20 = lowest_attack.take(range(20))\nlowest_attack_20.show()\nlowest_attack_20.group(\"is_legendary\")\n\n\n\n\nname\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nChansey\n5\n5\n30\n0\n\n\nHappiny\n5\n5\n130\n0\n\n\nMagikarp\n10\n55\n255\n0\n\n\nShuckle\n10\n230\n190\n0\n\n\nBlissey\n10\n10\n30\n0\n\n\nFeebas\n15\n20\n255\n0\n\n\nMetapod\n20\n55\n120\n0\n\n\nAbra\n20\n15\n200\n0\n\n\nLedyba\n20\n30\n255\n0\n\n\nTogepi\n20\n65\n190\n0\n\n\nMarill\n20\n50\n190\n0\n\n\nSmeargle\n20\n35\n45\n0\n\n\nAzurill\n20\n40\n150\n0\n\n\nMantyke\n20\n50\n25\n0\n\n\nSpewpa\n22\n60\n120\n0\n\n\nWynaut\n23\n48\n125\n0\n\n\nBronzor\n24\n86\n255\n0\n\n\nKakuna\n25\n50\n120\n0\n\n\nCleffa\n25\n28\n150\n0\n\n\nRalts\n25\n25\n235\n0\n\n\n\n\n\n\n\n\nis_legendary\ncount\n\n\n\n\n0\n20\n\n\n\n\n\nIt seems that the capture rate of the Pokemon is the best indicator of whether it is legendary or not. The attack and defense of the Pokemon may also be a good indicator."
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/index.html#training-and-testing-sets",
    "href": "projects/pokemon_legendary_classifier/index.html#training-and-testing-sets",
    "title": "Classifying Legendary Pokemon",
    "section": "Training and testing sets",
    "text": "Training and testing sets\n\npokemon_classify_columns = pokemon.select(\"attack\", \"defense\", \"capture_rate\", \"is_legendary\")\n\npokemon_classify_columns.stats()\n\n\n\n\nstatistic\nattack\ndefense\ncapture_rate\nis_legendary\n\n\n\n\nmin\n5\n5\n3\n0\n\n\nmax\n185\n230\n255\n1\n\n\nmedian\n75\n70\n60\n0\n\n\nsum\n62264\n58420\n79009\n70\n\n\n\n\n\n\nall_legendaries = pokemon_classify_columns.where(\"is_legendary\", are.equal_to(1)).sample(with_replacement=False)\nnon_legendaries = pokemon_classify_columns.where(\"is_legendary\", are.equal_to(0)).sample(with_replacement=False)\n\nnum_legendary = all_legendaries.num_rows\nnum_non_legendary = non_legendaries.num_rows\n\nnum_legendary_training = int(0.667 * num_legendary)\nnum_non_legendary_training = int(0.667 * num_non_legendary)\n\n\n# Take first two thirds legendary and non-legendary pokemon\ntraining_legendary = all_legendaries.take(np.arange(num_legendary_training))\ntraining_non_legendary = non_legendaries.take(np.arange(num_non_legendary_training))\n\n\n# Take last third legendary and non-legendary\ntesting_legendary = all_legendaries.take(np.arange(num_legendary_training, num_legendary))\ntesting_non_legendary = non_legendaries.take(np.arange(num_non_legendary_training, num_non_legendary))\n\n\n# Append training and testing legendary and non-legendary\ntesting_legendary.append(testing_non_legendary)\ntraining_legendary.append(training_non_legendary)\n\n\n# Shuffle training and testing and assign new names\ntraining = training_legendary.shuffle()\ntesting = testing_legendary.shuffle()\n\ntraining.relabel(\"is_legendary\", \"Class\")\ntesting.relabel(\"is_legendary\", \"Class\")\n\n\n\n\nattack\ndefense\ncapture_rate\nClass\n\n\n\n\n92\n108\n100\n0\n\n\n50\n120\n75\n0\n\n\n135\n105\n75\n0\n\n\n15\n20\n255\n0\n\n\n95\n95\n45\n0\n\n\n105\n90\n45\n0\n\n\n115\n60\n60\n0\n\n\n74\n74\n45\n0\n\n\n120\n75\n45\n0\n\n\n47\n75\n150\n0\n\n\n\n\n... (258 rows omitted)\n\n\nWe are putting two thirds of all the Pokemon into the training set, and the other third into the testing set. To make sure both sets have legendary Pokemon, first the legendary pokemon are separated from the non-legendary, and two thirds from each catagory are put into the training set, and the rest into the testing set.\n\nClassifier\n\ndef accuracy(predictions, labels):\n    diff = labels - predictions\n    num_incorrect = np.count_nonzero(diff)\n    num_correct = len(labels) - num_incorrect\n    accuracy = num_correct / len(labels)\n    return accuracy\n\n\ndef distance_nn(point1, point2):\n  \"\"\"The distance between two arrays of numbers.\"\"\"\n  return np.sqrt(np.sum((point1 - point2)**2))\n\ndef all_distances(training, point):\n  \"\"\"The distance between p (an array of numbers) and the numbers in row i of attribute_table.\"\"\"\n  attributes = training.drop('Class')\n  def distance_from_point(row):\n    return distance_nn(point, np.array(row))\n  return attributes.apply(distance_from_point)\n\ndef table_with_distances(training, point):\n  \"\"\"A copy of the training table with the distance from each row to array p.\"\"\"\n  return training.with_column('Distance', all_distances(training, point))\n\ndef closest(training, point, k):\n    \"\"\"A table containing the k closest rows in the training table to array p.\"\"\"\n    with_dists = table_with_distances(training, point)\n    sorted_by_distance = with_dists.sort('Distance')\n    topk = sorted_by_distance.take(np.arange(k))\n    return topk\n\ndef majority(topkclasses):\n  \"\"\"1 if the majority of the \"Class\" column is 1s, and 0 otherwise.\"\"\"\n  ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n  zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n  if ones &gt; zeros:\n    return 1\n  else:\n    return 0\n\ndef classify(training, p, k):\n  \"\"\"Classify an example with attributes p using k-nearest neighbor classification with the given training table.\"\"\"\n  closestk = closest(training, p, k)\n  topkclasses = closestk.select('Class')\n  return majority(topkclasses)\n\ndef classify_table(training, points, k):\n  \"\"\"Classify a table of unlabled points using KNN\"\"\"\n  def classify_p(p):\n    return classify(training, p, k)\n\n  classes = points.apply(classify_p)\n  return points.with_column('Class', classes)"
  },
  {
    "objectID": "projects/pokemon_legendary_classifier/index.html#classifying-legendary-pokemon",
    "href": "projects/pokemon_legendary_classifier/index.html#classifying-legendary-pokemon",
    "title": "Classifying Legendary Pokemon",
    "section": "Classifying Legendary Pokemon",
    "text": "Classifying Legendary Pokemon\n\nprediction_1 = classify_table(training, testing.drop(\"Class\"), 1)\nprediction_3 = classify_table(training, testing.drop(\"Class\"), 3)\nprediction_5 = classify_table(training, testing.drop(\"Class\"), 5)\n\n\naccuracy_1 = accuracy(prediction_1.column(\"Class\"), testing.column(\"Class\"))\naccuracy_3 = accuracy(prediction_3.column(\"Class\"), testing.column(\"Class\"))\naccuracy_5 = accuracy(prediction_5.column(\"Class\"), testing.column(\"Class\"))\n\nprint(\"k=1 -&gt;\", accuracy_1)\nprint(\"k=3 -&gt;\", accuracy_3)\nprint(\"k=5 -&gt;\", accuracy_5)\n\nk=1 -&gt; 0.9738805970149254\nk=3 -&gt; 0.9701492537313433\nk=5 -&gt; 0.9701492537313433\n\n\n\nResults\nThe classifier was run using a few different k-values for the k-nearest neighbor algorithm. Using the 1st nearest-neighbor, the accuracy was about 95%. Going to the 3 nearest neighbors, the accuracy went up to about 95.5%. With 5 nearest neighbors, the accuracy was 95.9%. Increasing the k-value just slightly increases the accuracy of the classifier."
  }
]